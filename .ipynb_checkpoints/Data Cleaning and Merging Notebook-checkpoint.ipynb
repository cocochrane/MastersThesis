{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Merging Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook cannot be run due to its reliance on data files that are not included here (because of IRB rules). However, its included here for the potential to help future projects that deal with the same or similiar databases. \n",
    "\n",
    "The data cleaning and merging protocol is as follows:  \n",
    "1. Define equivalencies for the column names (done by hand as different files have different column labels for the same feature). For each type of data, make a dictionary of these name equivalencies and which columns should be treated as strings during the future processing. \n",
    "2. Each file is cleaned and then all the data of the same type is merged together\n",
    "3. Calculate time features: Circadian Phase, Wake Period, and Hours Awake. Also calculate DecimalTime if not already present.\n",
    "4. Apply steps #1-3 for each data type (DSST, ADD, Moods, Raw PVT, Summary PVT, Raw Sleep, Summary Sleep, Subject information) and save the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import textwrap\n",
    "from simpledbf import Dbf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define Column Equivalencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSST_true_names = {\n",
    "  'LABTIME':['LABTIME','LABTIME,C,8','LABTIME.1'],\n",
    "  'SECONDS':['SECONDS'],\n",
    "  'SUBJECT':['SUBJECT','SUBJECT,C,9','Subj'],\n",
    "  'CONDITION': ['CONDITION', 'Condition'],\n",
    "  'DATE': ['DATE','DATE,D'],\n",
    "  'MILITARY TIME': ['TIME','TIME,C,8','MILITARY TIME'],\n",
    "  'DECIMALTIME': ['DECIMALTIME','CUMHRS','DEC TIME','DECTIME','Time','DecLabtime'],\n",
    "  'SCHEDULED': ['Scheduled', 'SCHEDULED'],\n",
    "  'CBT Circ Phase': ['CBT Circ Phase'],\n",
    "  'Day or night': ['Day or nigh', 'Day or night'],\n",
    "  'WP': ['WP','WAKE PERIOD'],\n",
    "  'Beat Cycle': ['Beat Cycle'],\n",
    "  'TEST': ['TEST', 'TEST.1'],\n",
    "  'SIT': ['SIT'],\n",
    "  'PROTOCOL': ['PROTOCOL'],\n",
    "  'SESSION': ['SESSION','SESSION,N,6,0'],\n",
    "  'TESTMSEC': ['TESTMSEC','TESTMSEC,N,5,0'],\n",
    "  'TEMPLATE': ['TEMPLATE','TEMPLATE,N,3,0'],\n",
    "  'CORRECT': ['CORRECT','CORRECT,N,3,0','perform','DSST correct'],\n",
    "  'WRONG': ['WRONG','WRONG,N,3,0'],\n",
    "  'TOTAL': ['TOTAL','TOTAL,N,3,0'],\n",
    "  'PERCENT': ['PERCENT','PERCENT,N,5,1'],\n",
    "  'REMINDERS': ['REMINDERS','REMINDERS,N,3,0'],\n",
    "  'MEANCORR': ['MEANCORR','MEANCORR,N,6,2'],\n",
    "  'MEANWRONG': ['MEANWRONG','MEANWRONG,N,6,2'],\n",
    "  'MEANOVER': ['MEANOVER','MEANOVER,N,6,2'],\n",
    "  'MEAN1ST': ['MEAN1ST','MEAN1ST,N,6,2'],\n",
    "  'N1ST': ['N1ST','N1ST,N,2,0'],\n",
    "  'MEAN2ND': ['MEAN2ND','MEAN2ND,N,6,2'],\n",
    "  'N2ND': ['N2ND','N2ND,N,2,0'],\n",
    "  'MEAN3RD': ['MEAN3RD','MEAN3RD,N,6,2'],\n",
    "  'N3RD': ['N3RD','N3RD,N,2,0'],\n",
    "  'RATEOVER': ['RATEOVER','RATEOVER,N,6,2'],\n",
    "  'RATE1ST': ['RATE1ST','RATE1ST,N,6,2'],\n",
    "  'RATE2ND': ['RATE2ND','RATE2ND,N,6,2'],\n",
    "  'RATE3RD': ['RATE3RD','RATE3RD,N,6,2'],\n",
    "  'PATTERN': ['PATTERN','PATTERN,C,9'],\n",
    "  'NOTES': ['NOTES','Comments','EDITNOTES,M']\n",
    "  }\n",
    "\n",
    "DSST_string_columns = ['SESSION', 'TEMPLATE', 'PROTOCOL', 'LABTIME', 'SUBJECT', 'DATE', 'MILITARY TIME', 'NOTES', 'TEST']\n",
    "\n",
    "PVT_true_names = {\n",
    " 'SUBJECT': ['SUBJECT','SUBJECT,C,10'], \n",
    " 'DATE': ['REALTIME','REALTIME,C,10','DATE'], \n",
    " 'LABTIME': ['LABTIME','LABTIME,C,10'], \n",
    " 'DECIMALTIME': ['DECTIME', 'Dec. Time', 'CUMHRS'], \n",
    " 'WP': ['WP','WAKE PERIOD'], \n",
    " 'WEEK': ['Week','WEEK'], \n",
    " 'TEST': ['TEST'],\n",
    " 'PROTOCOL': ['PROTOCOL','Protocol'], \n",
    " 'SCHEDULED': ['Scheduled','SCHEDULED'],\n",
    " 'SESSION': ['SESSION','SESSION,N,6,0'], \n",
    " 'NOTES': ['Comments','EDITNOTES,M','NOTES'],\n",
    " 'HAND': ['HAND','HAND,C,1'], \n",
    " 'ISIMIN': ['ISIMIN','ISIMIN,N,6,0'], \n",
    " 'ISIMAX': ['ISIMAX','ISIMAX,N,6,0'], \n",
    " 'COINC': ['COINC','COINC,N,6,0'], \n",
    " 'WRONG': ['WRONG','WRONG,N,6,0'], \n",
    " 'ANT_BAD': ['ANT_BAD','ANT_BAD,N,6,0'], \n",
    " 'ANT_GOOD': ['ANT_GOOD','ANT_GOOD,N,6,0'], \n",
    " 'TIMEOUT': ['TIMEOUT','TIMEOUT,N,6,0'], \n",
    " 'ALL_MEAN': ['ALL_MEAN','ALL_MEAN,N,8,2'], \n",
    " 'ALL_MED': ['ALL_MED','ALL_MED,N,8,2'], \n",
    " 'ALL_STD': ['ALL_STD','ALL_STD,N,8,2'], \n",
    " 'SLOW_MEAN': ['SLOW_MEAN','SLOW_MEAN,N,8,2'],\n",
    " 'SLOW_STD': ['SLOW_STD','SLOW_STD,N,8,2'], \n",
    " 'FAST_MEAN': ['FAST_MEAN','FAST_MEAN,N,8,2'], \n",
    " 'FAST_STD': ['FAST_STD','FAST_STD,N,8,2'], \n",
    " 'IALL_MEAN': ['IALL_MEAN','IALL_MEAN,N,8,2'],\n",
    " 'IALL_MED': ['IALL_MED','IALL_MED,N,8,2'], \n",
    " 'IALL_STD': ['IALL_STD','IALL_STD,N,8,2'], \n",
    " 'N': ['N','N,N,6,0'], \n",
    " 'ISLOW_MEAN': ['ISLOW_MEAN','ISLOW_MEAN,N,8,2'], \n",
    " 'ISLOW_STD': ['ISLOW_STD','ISLOW_STD,N,8,2'], \n",
    " 'ISLOW_N': ['ISLOW_N','ISLOW_N,N,6,0'], \n",
    " 'IFAST_MEAN': ['IFAST_MEAN','IFAST_MEAN,N,8,2'], \n",
    " 'IFAST_STD': ['IFAST_STD','IFAST_STD,N,8,2'], \n",
    " 'IFAST_N': ['IFAST_N','IFAST_N,N,6,0'], \n",
    " 'LAPSES': ['LAPSES','LAPSES,N,6,0'], \n",
    " 'LAPSE_TRAN': ['LAPSE_TRAN','LAPSE_TRAN,N,8,2'], \n",
    " 'LAPSE_SLOW': ['LAPSE_SLOW','LAPSE_SLOW,N,6,0'], \n",
    " 'LAPSE_PERC': ['LAPSE_PERC','LAPSE_PERC,N,8,2'], \n",
    " 'SLOPE': ['SLOPE','SLOPE,N,8,2'], \n",
    " 'INTERCEPT': ['INTERCEPT','INTERCEPT,N,8,2'], \n",
    " 'I_INTER': ['I_INTER','I_INTER,N,8,2'], \n",
    " 'CORR': ['CORR','CORR,N,8,2'], \n",
    " 'RSQUARE': ['RSQUARE','RSQUARE,N,8,2'],\n",
    " 'Difference': ['Difference'],\n",
    " 'Compare': ['Compare']}\n",
    "\n",
    "PVT_string_columns = ['HAND','TEST','SESSION', 'TEMPLATE', 'PROTOCOL', 'LABTIME', 'SUBJECT', 'DATE', 'MILITARY TIME', 'NOTES', 'TEST']\n",
    "\n",
    "PVTDetail_true_names = {\n",
    "    'SUBJECT': ['SUBJECT', 'SUBJECT,C,25', 'SUBJECT,C,10'],\n",
    "    'LABTIME': ['LABTIME', 'LABTIME,C,10'],\n",
    "    'SESSION': ['SESSION', 'SESSION,N,6,0'],\n",
    "    'HAND': ['HAND', 'HAND,C,1'],\n",
    "    'TRIAL': ['TRIAL,N,6,0', 'TRIAL'],\n",
    "    'STARTED': ['STARTED', 'STARTED,N,8,0'],\n",
    "    'DELAY': ['DELAY', 'DELAY,N,6,0'],\n",
    "    'RT': ['RT', 'RT,N,6,0'],\n",
    "    'BUTTON':['BUTTON','BUTTON,C,1']\n",
    "}\n",
    "\n",
    "PVTDetail_string_columns = ['HAND', 'LABTIME', 'SUBJECT', 'BUTTON']\n",
    "\n",
    "ADD_true_names = {\n",
    "  'LABTIME':['LABTIME','LABTIME,C,8','LABTIME.1'],\n",
    "  'SECONDS':['SECONDS'],\n",
    "  'SUBJECT':['SUBJECT','SUBJECT,C,9','Subj', 'Subject'],\n",
    "  'DATE': ['DATE','DATE,D'],\n",
    "  'MILITARY TIME': ['TIME','TIME,C','TIME,C,8','MILITARY TIME'],\n",
    "  'SCHEDULED': ['Scheduled', 'SCHEDULED'],\n",
    "  'WP': ['WP', 'WAKE PERIOD'],\n",
    "  'TEST': ['TEST','TEST.1'],\n",
    "  'SIT': ['SIT'],\n",
    "  'DECIMALTIME': ['Time','CUMHRS', 'DEC TIME','DecLabtime', 'DECTIME','DECIMALTIME'],\n",
    "  'Beat Cycle': ['Beat Cycle'],\n",
    "  'PROTOCOL': ['PROTOCOL'],\n",
    "  'CONDITION': ['CONDITION', 'Condition'],\n",
    "  'SESSION': ['SESSION','SESSION,N,6,0'],\n",
    "  'TESTMSEC': ['TESTMSEC','TESTMSEC,N,5,0'],\n",
    "  'TEMPLATE': ['TEMPLATE','TEMPLATE,N,3,0'],\n",
    "  'WRONG': ['WRONG','WRONG,N,3,0'],\n",
    "  'TOTAL': ['TOTAL','TOTAL,N,3,0'],\n",
    "  'Percent correct': ['Percent correct'],\n",
    "  'REMINDERS': ['REMINDERS','REMINDERS,N,3,0'],\n",
    "  'MEANCORR': ['MEANCORR','MEANCORR,N,6,2'],\n",
    "  'MEANWRONG': ['MEANWRONG','MEANWRONG,N,6,2'],\n",
    "  'MEANOVER': ['MEANOVER','MEANOVER,N,6,2'],\n",
    "  'MEAN1ST': ['MEAN1ST','MEAN1ST,N,6,2'],\n",
    "  'N1ST': ['N1ST','N1ST,N,2,0'],\n",
    "  'MEAN2ND': ['MEAN2ND','MEAN2ND,N,6,2'],\n",
    "  'N2ND': ['N2ND','N2ND,N,2,0'],\n",
    "  'MEAN3RD': ['MEAN3RD','MEAN3RD,N,6,2'],\n",
    "  'N3RD': ['N3RD','N3RD,N,2,0'],\n",
    "  'RATEOVER': ['RATEOVER','RATEOVER,N,6,2'],\n",
    "  'RATE1ST': ['RATE1ST','RATE1ST,N,6,2'],\n",
    "  'RATE2ND': ['RATE2ND','RATE2ND,N,6,2'],\n",
    "  'RATE3RD': ['RATE3RD','RATE3RD,N,6,2'],\n",
    "  'PATTERN': ['PATTERN','PATTERN,C,9'],\n",
    "  'VERSION': ['VERSION'],\n",
    "  'ATTEMPTED':['ATTEMPTED'],\n",
    "  'CORRECT':['CORRECT','correct'],\n",
    "  'TIMESECS':['TIMESECS'],\n",
    "  'SOUND':['SOUND'],\n",
    "  'NOTES': ['NOTES','EDITNOTES','EDITNOTES,M','Comments'],\n",
    " }\n",
    "\n",
    "ADD_string_columns = ['SOUND','TEST','SESSION', 'TEMPLATE', 'PROTOCOL', 'LABTIME', 'SUBJECT', 'DATE', 'MILITARY TIME', 'NOTES']\n",
    "\n",
    "Moods_true_names = {'LABTIME':['LABTIME','LABTIME,C,8','LABTIME.1'],\n",
    "  'SECONDS':['SECONDS','SECONDS,C,2'],\n",
    "  'SUBJECT':['SUBJECT','SUBJECT,C,9','Subj'],\n",
    "  'DATE': ['DATE','DATE,D'],\n",
    "  'MILITARY TIME': ['TIME','TIME,C','TIME,C,8','MILITARY TIME'],\n",
    "  'SCHEDULED': ['Scheduled', 'SCHEDULED'],\n",
    "  'WP': ['WP', 'WAKE PERIOD'],\n",
    "  'TEST': ['TEST','TEST.1'],\n",
    "  'SIT': ['SIT'],\n",
    "  'DECIMALTIME': ['Time','CUMHRS', 'DEC TIME','DecLabtime', 'DECTIME', 'DECIMALTIME','Dec. Time'],\n",
    "  'Beat Cycle': ['Beat Cycle'],\n",
    "  'PROTOCOL': ['PROTOCOL'],\n",
    "  'CONDITION': ['CONDITION', 'Condition'],\n",
    "  'SESSION': ['SESSION','SESSION,N,6,0'],\n",
    "  'ALERT':['ALERT','ALERT,N,7,2'],\n",
    "  'SAD':['SAD','SAD,N,7,2'],\n",
    "  'CALM':['CALM','CALM,N,7,2'],\n",
    "  'STRONG':['STRONG','STRONG,N,7,2'],\n",
    "  'CLEARHEADED': ['CLEARHEADED','CLEARHEADE','CLEARHEADE,N,7,2'],\n",
    "  'WELLCOORDINATED': ['WELLCOORDINATED','WELLCOORDI','WELLCOORDI,N,7,2'],\n",
    "  'ENERGETIC': ['ENERGETIC','ENERGETIC,N,7,2'],\n",
    "  'CONTENTED': ['CONTENTED','CONTENTED,N,7,2'],\n",
    "  'TRANQUIL': ['TRANQUIL','TRANQUIL,N,7,2'],\n",
    "  'QUICKWITTE': ['QUICKWITTE','QUICKWITTED','QUICKWITTE,N,7,2'],\n",
    "  'RELAXED': ['RELAXED','RELAXED,N,7,2'],\n",
    "  'ATTENTIVE': ['ATTENTIVE','ATTENTIVE,N,7,2'],\n",
    "  'COMPETENT': ['COMPETENT','COMPETENT,N,7,2'],\n",
    "  'FRIENDLY': ['FRIENDLY','FRIENDLY,N,7,2'],\n",
    "  'INTERESTED': ['INTERESTED','INTERESTED,N,7,2'],\n",
    "  'SOCIABLE': ['SOCIABLE','SOCIABLE,N,7,2'],\n",
    "  'DIFFER': ['DIFFER'],\n",
    "  'WARM': ['WARM','WARM,N,7,2'],\n",
    "  'INTERESTED': ['INTERESTED','INTERESTED,N,7,2'],\n",
    "  'NOTES': ['NOTES','EDITNOTES','EDITNOTES,M','Comments'],\n",
    " }\n",
    "\n",
    "Moods_string_columns = ['Beat Cycle','CONDITION','DIFFER', 'TEST', 'SESSION', 'TEMPLATE', 'PROTOCOL', 'LABTIME', 'SUBJECT', 'DATE', 'MILITARY TIME', 'NOTES']\n",
    "\n",
    "Subject_true_names = {\n",
    "    'SUBJECT': ['SUBJECT', 'Subject'],\n",
    "    'STUDY': ['Study', 'STUDY'], \n",
    "    'Age':['Age'], \n",
    "    'Gender': ['Gender'], \n",
    "    'Age Group': ['Age Group'], \n",
    "    'Morningness-Eveningness Scale':['Morningness-Eveningness Scale'], \n",
    "    'Hab/CSR': ['Hab/CSR'], \n",
    "    'Hab Wake':['Hab Wake'], \n",
    "    'Hab Bed': ['Hab Bed'], \n",
    "    'EST/DST':['EST/DST'], \n",
    "    'FD T-cycle': ['FD T-cycle'], \n",
    "    'FD SP length':['FD SP length'], \n",
    "    'FD WP Length': ['FD WP Length'], \n",
    "    'Start analysis':['Start analysis'], \n",
    "    'End Analysis': ['End Analysis'], \n",
    "    'check':['check'], \n",
    "    'Start analysis SPn': ['Start analysis SPn'], \n",
    "    'End analysis SPn (included)':['End analysis SPn (included)'], \n",
    "    'Mel Tau': ['Mel Tau'], \n",
    "    'Mel Comp Amp':['Mel Comp Amp'], \n",
    "    'MelAmp Circad': ['MelAmp Circad'], \n",
    "    'Mel - Amp T':['Mel - Amp T'], \n",
    "    'Mel Comp Max': ['Mel Comp Max'], \n",
    "    'Mel Fund Max': ['Mel Fund Max']\n",
    "}\n",
    "Subject_string_columns = ['Hab/CSR','SUBJECT', 'STUDY', 'Age Group', 'EST/DST', 'Gender']\n",
    "\n",
    "Sleep_true_names = {\n",
    "    'SUBJECT': ['SUBJECT', 'Subject'],\n",
    "    'STUDY': ['STUDY', 'Study'],\n",
    "    'SPn': ['SPn'],\n",
    "    'latS1': ['latS1'],\n",
    "    'latS2': ['latS2'],\n",
    "    'latREM': ['latREM'],\n",
    "    'latSWS': ['latSWS'],\n",
    "    'latPersistSLeep': ['latPersistSLeep'],\n",
    "    'S1': ['S1'],\n",
    "    'S2': ['S2'],\n",
    "    'S3': ['S3'],\n",
    "    'S4': ['S4'],\n",
    "    'Scheduled Length': ['Scheduled Length'],\n",
    "    'Wake': ['Wake'],\n",
    "    'REM': ['REM'],\n",
    "    'Other': ['Other'],\n",
    "    'WAPSO': ['WAPSO'],\n",
    "    'FinalWake': ['FinalWake'],\n",
    "    'NWake': ['NWake'],\n",
    "    'LoutToLon': ['LoutToLon'],\n",
    "    'Type': ['Type'],\n",
    "    'Scheduled': ['Scheduled'],\n",
    "    'Length': ['Length'],\n",
    "    'missing': ['missing'],\n",
    "    'Total time': ['Total time'],\n",
    "    'Sleep Efficiency': ['Sleep Efficiency'],\n",
    "    'TST': ['TST'],\n",
    "    'SWS': ['SWS'],\n",
    "    'Wake before 1st sleep': ['Wake before 1st sleep'],\n",
    "    'WPn': ['WPn'],\n",
    "    'last epoch before lights on': ['last epoch before lights on'],\n",
    "    'prev wake': ['prev wake']\n",
    "}\n",
    "Sleep_string_columns = ['SUBJECT', 'STUDY', 'Type', 'prev wake']\n",
    "\n",
    "SleepDetail_true_names = {\n",
    "    'DECIMALTIME': ['DECIMALTIME', 'LABTIME']\n",
    "}\n",
    "SleepDetail_string_columns = ['SUBJECT', 'LABTIME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'DSST': {'ColNames': DSST_true_names, 'StringCols': DSST_string_columns},\n",
    "    'PVT': {'ColNames': PVT_true_names, 'StringCols': PVT_string_columns},\n",
    "    'ADD': {'ColNames': ADD_true_names, 'StringCols': ADD_string_columns},\n",
    "    'Moods': {'ColNames': Moods_true_names, 'StringCols': Moods_string_columns},\n",
    "    'Subject Info': {'ColNames': Subject_true_names, 'StringCols': Subject_string_columns},\n",
    "    'Sleep': {'ColNames': Sleep_true_names, 'StringCols': Sleep_string_columns},\n",
    "    'PVT Detail': {'ColNames': PVTDetail_true_names, 'StringCols': PVTDetail_string_columns},\n",
    "    'Sleep Detail': {'ColNames': SleepDetail_true_names, 'StringCols': SleepDetail_string_columns}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean Individual Files and Merge Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(prefix, data):\n",
    "    prefix = \"     \" + prefix\n",
    "    preferredWidth = 70\n",
    "    wrapper = textwrap.TextWrapper(initial_indent=prefix, width=preferredWidth,\n",
    "                               subsequent_indent=' '*len(prefix))\n",
    "    return wrapper.fill(str(data))\n",
    "\n",
    "def get_patient_info():\n",
    "    \"\"\" Reads the patient information file and produces \n",
    "    a dictionary of {patient_number: {feature_names: value}}\"\"\"\n",
    "    \n",
    "    subject_info = 'Subject Info/FD subj info 2017a.csv'\n",
    "    subj = pd.read_csv(subject_info, index_col = 0)\n",
    "    subject_info_dict = subj.to_dict(orient = 'index')\n",
    "    return subject_info_dict\n",
    "\n",
    "def capitalize_subject_names(row):\n",
    "    \"\"\"Capitalize subject names to promote consistency\"\"\"\n",
    "    subj = row.SUBJECT\n",
    "    new_subj = ''\n",
    "    for i in subj:\n",
    "        if i.isalpha() and i.islower():\n",
    "            new_subj += i.upper()\n",
    "        else:\n",
    "            new_subj += i\n",
    "    return new_subj\n",
    "\n",
    "def delete_bad_rows(p):\n",
    "    \"\"\"This function deletes any rows that are found in the \n",
    "    raw data files which contain the string MD. These indicate problem\n",
    "    data and therefore we eliminate them\"\"\"\n",
    "    rows_to_delete = []\n",
    "    for row in range(len(p.index)):\n",
    "        for col in range(len(p.columns)):\n",
    "            if p.iloc[row,col] == 'MD':\n",
    "                rows_to_delete.append(row)\n",
    "    \n",
    "    print(pretty_print(\"Delete rows: \", list(set(rows_to_delete))))\n",
    "    p = p.drop(p.index[list(set(rows_to_delete))])\n",
    "    return p\n",
    "\n",
    "def clean_file(df, missing_data, dict_name, folder, columns_to_exclude_by, patient_list):\n",
    "    \"\"\" This is the main cleaning function: empty rows and columns are deleted,\n",
    "    rows with invalid subject names or with MD values, subject names are captialized\n",
    "    for consistency, and missing data types are converted to nan.\n",
    "    \"\"\" \n",
    "    #remove empty columns and rows\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    if folder != 'Sleep Detail':\n",
    "        for i in list(df):\n",
    "            if 'Unnamed' in i:\n",
    "                del df[i]\n",
    "        df = convert_column_names(df, dict_name, columns_to_exclude_by )\n",
    "    else:\n",
    "        if len(list(df)) > 4:\n",
    "            print(pretty_print(\"More than 4 columns: \", df.columns))\n",
    "            df.columns = ['SUBJECT', 'WP/SP', 'LABTIME', 'Sleep Stage', 'Unnamed']\n",
    "            del df['Unnamed']\n",
    "        else:\n",
    "            df.columns = ['SUBJECT', 'WP/SP', 'LABTIME', 'Sleep Stage']\n",
    "        #delete other patients\n",
    "        df = df[df['SUBJECT'].isin(patient_list)]\n",
    "    \n",
    "    #delete invalid subjects\n",
    "    df = df.loc[~(df['SUBJECT'].isin([np.nan,'nan','.']))]\n",
    "    \n",
    "    #delete rows with MD\n",
    "    if folder != 'PVT Detail' and folder != 'Sleep Detail':\n",
    "        df = delete_bad_rows(df)\n",
    "    \n",
    "    #capitalize subject names\n",
    "    df.loc[:, 'SUBJECT'] = df.apply(capitalize_subject_names, axis = 1)\n",
    "    \n",
    "    #convert other missing datatypes to Nan\n",
    "    df = df.replace(missing_data, np.nan)\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_column_names(df, dict_name, columns_to_exclude_by):\n",
    "    \"\"\" Duplicate columns or columns we do not need (as defined\n",
    "    by the dictionary created in step #1) are deleted. \n",
    "    Also if there are any columns that are meant to encode whether\n",
    "    the row should be ignored (columns_to_exclude_by), then the \n",
    "    data is treated accordingly. The names of any deleted columns \n",
    "    are printed out for inspection.\n",
    "    \"\"\"\n",
    "    labels_conversion_dictionary = {}\n",
    "    for i in dict_name:\n",
    "        for j in dict_name[i]:\n",
    "            labels_conversion_dictionary[j] = i\n",
    "         \n",
    "    new_names = []\n",
    "    dup_col = []\n",
    "    unneeded_col = []\n",
    "    exclude = []\n",
    "    for i in list(df):\n",
    "        if i in columns_to_exclude_by:\n",
    "            df = df[df[i] == 1]\n",
    "            del df[i]\n",
    "            exclude.append(i)\n",
    "            \n",
    "        else:\n",
    "            try: \n",
    "                name = labels_conversion_dictionary[i]\n",
    "                if name in new_names: \n",
    "                    dup_col.append(name)\n",
    "                    del df[i]\n",
    "                else:\n",
    "                    new_names.append(name)\n",
    "            except:\n",
    "                unneeded_col.append(i)\n",
    "                del df[i]        \n",
    "    df.columns = new_names\n",
    "    \n",
    "    print(pretty_print(\"Deleting duplicate columns: \", dup_col))\n",
    "    print(pretty_print(\"Exclude data based on: \", exclude))\n",
    "    print(pretty_print(\"Deleting columns: \", unneeded_col))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_files(folder, strings, columns_to_delete_by, missing_data):\n",
    "    \"\"\"Reads and cleans all files in given folder then merges them together\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    folder: folder for files to clean\n",
    "    strings: names of tabs to consider in Excel files\n",
    "    columns_to_delete_by: names of exclusion columns like \"Include\" with which to delete data by\n",
    "    \"\"\"\n",
    "    \n",
    "    patient_dict = get_patient_info()\n",
    "    patient_list = list(patient_dict)\n",
    "    data_frames = []\n",
    "    patients = []\n",
    "    for f in os.listdir(os.getcwd()+\"/\"+folder):\n",
    "        flag = True\n",
    "        print(\"File is: \", f)\n",
    "        if  f.endswith('.xls') or  f.endswith('.csv') or f.endswith('.xlsx'):\n",
    "            name = f.split('.')[0]\n",
    "            \n",
    "            #Read excel files \n",
    "            if f.endswith('.xls') or f.endswith('.xlsx'):\n",
    "                p = pd.ExcelFile(os.getcwd()+\"/\"+folder+\"/\"+f)\n",
    "                tab_names = p.sheet_names\n",
    "                \n",
    "                #parse tab of interest\n",
    "                none = 0\n",
    "                for s in strings:\n",
    "                    if s in tab_names:\n",
    "                        df = p.parse(s)\n",
    "                        none = 1\n",
    "                if none == 0: #flag for no tab of interest\n",
    "                    print(\"PROBLEM\")\n",
    "\n",
    "            #read CSV files\n",
    "            elif f.endswith('.csv'):\n",
    "                if folder == 'Sleep Detail':\n",
    "                    new_subj = ''\n",
    "                    for i in f[:f.find('Slp')] :\n",
    "                        if i.isalpha() and i.islower():\n",
    "                            new_subj += i.upper()\n",
    "                        else:\n",
    "                            new_subj += i\n",
    "                \n",
    "                    if new_subj in patient_list:\n",
    "                        df = pd.read_csv(os.getcwd()+\"/\"+folder+\"/\"+f, header = None,encoding=\"latin-1\")\n",
    "                    else:\n",
    "                        print(pretty_print('Not considering', f[:f.find('Slp')]))\n",
    "                        flag = False\n",
    "                else:\n",
    "                    df = pd.read_csv(os.getcwd()+\"/\"+folder+\"/\"+f,encoding=\"latin-1\")\n",
    "                    \n",
    "            if flag:\n",
    "                print(pretty_print(\"Original dataframe size: \", df.shape))\n",
    "                df = clean_file(df, missing_data,d[folder]['ColNames'], folder, columns_to_delete_by, patient_list)\n",
    "                print(pretty_print(\"After Cleaning: \", df.shape))\n",
    "                data_frames.append(df)\n",
    "            \n",
    "    #merge all files together\n",
    "    curr = data_frames[0]\n",
    "    for i in range(1,len(data_frames)):\n",
    "        curr = pd.merge(curr, data_frames[i], how='outer')\n",
    "    print(curr.shape)\n",
    "    return curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calculate Time Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_info = 'Subject Info/FD subj info 2017a.csv'\n",
    "subj = pd.read_csv(subject_info, index_col = 0)\n",
    "subject_info_dict = subj.to_dict(orient = 'index') \n",
    "\n",
    "def circadian_phase(row):\n",
    "    \"\"\"Calculate Circadian Phase using Time, Mel Tau, and Mel Fund Max,\n",
    "    if available.\"\"\"\n",
    "    subject = row.SUBJECT\n",
    "    start = subject_info_dict[subject]['Start analysis']\n",
    "    end = subject_info_dict[subject]['End Analysis']\n",
    "    \n",
    "    if row.DecimalTime >= start and row.DecimalTime <= end:\n",
    "        try:\n",
    "            tau = float(subject_info_dict[subject]['Mel Tau'])\n",
    "            fundMax = float(subject_info_dict[subject]['Mel Fund Max'])\n",
    "            time = float(row.DecimalTime)\n",
    "        except:\n",
    "            return np.nan\n",
    "        return ((time-fundMax) % tau) * (24.0/tau)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def correct_time(row):\n",
    "    \"\"\"If Decimal time is present, return it. Otherwise, calculate\n",
    "    Decimal time based on Labtime.\"\"\"\n",
    "    try:\n",
    "        if type(row.DECIMALTIME) == float and math.isnan(row.DECIMALTIME):\n",
    "            a = row.LABTIME.split(':')\n",
    "            return float(a[0]) + float(a[1])/60\n",
    "        else:\n",
    "            return row.DECIMALTIME\n",
    "    except:\n",
    "        try:\n",
    "            return float(row.LABTIME)\n",
    "        except:\n",
    "            a = str(row.LABTIME).split(':')\n",
    "            return float(a[0]) + float(a[1])/60\n",
    "    \n",
    "def Hours_awake(row):\n",
    "    \"\"\"Calculate Hours Awake\"\"\"\n",
    "    patient = row.SUBJECT\n",
    "    start = subject_info_dict[patient]['Start analysis']\n",
    "    end = subject_info_dict[patient]['End Analysis']\n",
    "    \n",
    "    if row.DecimalTime >= start and row.DecimalTime <= end:\n",
    "        tcycle = float(subject_info_dict[patient]['FD T-cycle'])\n",
    "        return (row.DecimalTime-start) % tcycle\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "    \n",
    "def WakePeriod(row):\n",
    "    \"\"\"Calculate Wake Period\"\"\"\n",
    "    patient = row.SUBJECT\n",
    "    start = subject_info_dict[patient]['Start analysis']\n",
    "    end = subject_info_dict[patient]['End Analysis']\n",
    "    \n",
    "    if row.DecimalTime >= start and row.DecimalTime <= end:\n",
    "        a = math.floor((row.DecimalTime-start)/float(subject_info_dict[patient]['FD T-cycle']))\n",
    "        a = a + int(subject_info_dict[patient]['Start analysis SPn'])\n",
    "        \n",
    "        try:\n",
    "            if pd.isnull(row.WP) or row.WP == np.nan:\n",
    "                return int(a)\n",
    "            else:\n",
    "                if a != row.WP:\n",
    "                    print('Discrepancy', row.SUBJECT, row.DecimalTime, a, row.WP)\n",
    "                    return a\n",
    "                return row.WP\n",
    "        except:\n",
    "            return int(a)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def Feature_Types_and_Calculations(df, folder):\n",
    "    \"\"\"Calculate Circadian Phase, Hours Awake and Wake Period.\n",
    "    If the time is in LABTIME format then convert to DecimalTime.\n",
    "    \"\"\"\n",
    "    string_cols = d[folder]['StringCols']\n",
    "    numeric_cols = [i for i in list(df) if i not in string_cols]\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric)\n",
    "    \n",
    "    if folder != 'Subject Info' and folder != 'Sleep':\n",
    "        df.loc[:, 'DecimalTime'] = df.apply(correct_time, axis = 1)\n",
    "        if folder != 'Sleep Detail' and folder != 'Sleep':    \n",
    "            df.loc[:, 'CircadianPhase'] = df.apply(circadian_phase, axis = 1)\n",
    "            df.loc[:, 'HoursAwake'] = df.apply(Hours_awake, axis = 1)\n",
    "            df.loc[:, 'WakePeriod'] = df.apply(WakePeriod, axis = 1)\n",
    "\n",
    "    #delete other time columns\n",
    "    for col in ['LABTIME','SECONDS','DATE','MILITARY TIME','DECIMALTIME']:\n",
    "        if col in df.columns:\n",
    "            del df[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Run Code for Each Data Type and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'DSST'\n",
    "file_tab_names = ['DSST-uev', 'FEV', 'All']\n",
    "columns_to_exclude_by = []\n",
    "missing_data = ['.', '-999', \"\", \" \"]\n",
    "\n",
    "dsst = read_all_files(file_type, file_tab_names, columns_to_exclude_by, missing_data)\n",
    "dsst2 = Feature_Types_and_Calculations(dsst, file_type)\n",
    "dsst2.to_csv(file_type+\"_Data_Merged.csv\", index = False, na_rep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'PVT'\n",
    "file_tab_names = ['acceptable', 'FEV', 'PVTALL-fev', 'PVTALL-FEV']\n",
    "columns_to_delete_by = ['Include', 'Valid data', 'good']\n",
    "missing_data = ['.', '-999', \"\", \" \"]\n",
    "\n",
    "pvt = read_all_files(file_type, file_tab_names, columns_to_delete_by, missing_data)\n",
    "pvt2 = Feature_Types_and_Calculations(pvt, file_type)\n",
    "pvt2.to_csv(file_type+\"_Data_Merged.csv\", index = False, na_rep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'ADD'\n",
    "file_tab_names = ['FEV']\n",
    "missing_data = ['.', '-999', \"\", \" \"]\n",
    "\n",
    "add = read_all_files(file_type, file_tab_names, [], missing_data)\n",
    "add2 = Feature_Types_and_Calculations(add, file_type)\n",
    "add2.to_csv(file_type+\"_Data_Merged.csv\", index = False, na_rep = \"\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'Moods'\n",
    "file_tab_names = ['SCALES-uev','FEV']\n",
    "missing_data = ['.', '-999', \"\", \" \"]\n",
    "\n",
    "moods = read_all_files(file_type, file_tab_names, [], missing_data)\n",
    "moods2 = Feature_Types_and_Calculations(moods, file_type)\n",
    "moods2.to_csv(file_type+\"_Data_Merged.csv\", index = False, na_rep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'Subject Info'\n",
    "file_tab_names = []\n",
    "missing_data = ['.', '-999', \"\", \" \"]\n",
    "\n",
    "subject = read_all_files(file_type, file_tab_names, [], missing_data)\n",
    "subject2 = Feature_Types_and_Calculations(subject, file_type)\n",
    "subject.to_csv(file_type+\"_Data_Merged.csv\", index = False, na_rep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'Sleep'\n",
    "file_tab_names = []\n",
    "missing_data = ['.', '-999', \"\", \" \", '#REF!', '#VALUE!']\n",
    "\n",
    "sleep = read_all_files(file_type, file_tab_names, ['IfUse'], missing_data)\n",
    "sleep2 = Feature_Types_and_Calculations(sleep, file_type)\n",
    "sleep2.to_csv(file_type+\"_Data_Merged.csv\", index = False, na_rep = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'PVT Detail'\n",
    "file_tab_names = []\n",
    "missing_data = ['.', '-999', \"\", \" \"]\n",
    "\n",
    "pvtdetail = read_all_files(file_type, file_tab_names, ['IfUse'], missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type = 'Sleep Detail'\n",
    "file_tab_names = []\n",
    "missing_data = ['.', '-999', \"\", \" \"]\n",
    "\n",
    "sleepdetail = read_all_files(file_type, file_tab_names, ['IfUse'], missing_data)\n",
    "\n",
    "sleepdetail2 = Feature_Types_and_Calculations(sleepdetail, file_type)\n",
    "sleepdetail2.to_csv(file_type+\"_Data_Merged.csv\", index = False, na_rep = \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
