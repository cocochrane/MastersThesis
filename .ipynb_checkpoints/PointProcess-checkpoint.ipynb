{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the classes IGPointProcess and HDIGPointProcess which fit a renewal inverse guassian and a history-dependent inverse gaussian, respectively. Also there are two classes for collecting features from the fitted distributions: Collect_IG_Data and Collect_HDIG_Data.\n",
    "\n",
    "The IGPointProcess class takes a list of reaction times as its one parameter. The Collect_IG_Data class takes one parameter: the participant_dict attribute from the Participants class. The function collectAndSaveData() collects the features and saves them to the PVTSummaryData.csv file. \n",
    "\n",
    "The HDIGPointProcess class takes three parameters: a list of reaction times, a value p which specifies the number of previous reaction times to use, and a value alpha which specifies the weighting factor in the weighting function. The Collect_HDIG_Data class takes three parameters: p, alpha, and the participant_dict attribute from the Participants class. The function collectAndSaveData() collects the features and saves them to the PVTSummaryData.csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython version:       6.2.1 (newest at 6.1.0)\n",
      "Numpy version:        1.13.3 (newest at 1.13.1)\n",
      "SciPy version:        0.19.1 (newest at 0.19.1)\n",
      "Pandas version:       0.20.3 (newest at 0.20.3)\n",
      "Mapltolib version:     2.1.0 (newest at 2.0.2)\n",
      "Scikit-Learn version: 0.19.0 (newest at 0.19.0)\n",
      "MNE version:          0.14.1 (newest at 0.14.1)\n"
     ]
    }
   ],
   "source": [
    "#IPython is what you are using now to run the notebook\n",
    "import IPython\n",
    "print (\"IPython version:      %6.6s (newest at 6.1.0)\" % IPython.__version__)\n",
    "\n",
    "# Numpy is a library for working with Arrays\n",
    "import numpy as np\n",
    "print (\"Numpy version:        %6.6s (newest at 1.13.1)\" % np.__version__)\n",
    "\n",
    "# SciPy implements many different numerical algorithms\n",
    "import scipy as sp\n",
    "print (\"SciPy version:        %6.6s (newest at 0.19.1)\" % sp.__version__)\n",
    "\n",
    "# Pandas makes working with data tables easier\n",
    "import pandas as pd\n",
    "print (\"Pandas version:       %6.6s (newest at 0.20.3)\" % pd.__version__)\n",
    "\n",
    "# Module for plotting\n",
    "import matplotlib \n",
    "print (\"Mapltolib version:    %6.6s (newest at 2.0.2)\" % matplotlib.__version__)\n",
    "\n",
    "# SciKit Learn implements several Machine Learning algorithms\n",
    "import sklearn\n",
    "print (\"Scikit-Learn version: %6.6s (newest at 0.19.0)\" % sklearn.__version__)\n",
    "\n",
    "# MNE is a package for processing (EEG) and (MEG) data \n",
    "import mne\n",
    "print (\"MNE version:          %6.6s (newest at 0.14.1)\" % mne.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import peakutils as pku\n",
    "from peakutils.plot import plot as pplot\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.optimize import minimize,fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renewal Inverse Gaussian Model \n",
    "\n",
    "Treats the reaction times as independent. Let $t-u_k$ be the current time since the previous reaction, and $u_k$ be the time of $k$th reaction. With independent heartbeats, $p=0$ and the history component is irrelevant.\n",
    "\n",
    "$$H_{u_k}=(u_k, u_k-u_{k-1}, ... , u_{k-p+1}-u_{k-p})=(u_k, w_k, ... , w_{k-p+1})$$\n",
    "\n",
    "$$\\theta=(\\theta_0, \\theta_1, ... , \\theta_{p+1})$$\n",
    "\n",
    "$$\\mu(H_{u_k}, \\theta)=\\theta_0+\\sum_{j=1}^p \\theta_j w_{k-j+1}=\\theta_0,$$\n",
    "\n",
    "$$f(t|H_{u_k} , \\theta)=f(t|\\theta_0, \\theta_1)=\\big[ \\frac{\\theta_{1}}{2\\pi(t-u_k)^3} \\big] ^\\frac{1}{2} exp \\big(-\\frac{\\theta_{1}[t-u_k-\\theta_0)]^2}{2\\theta_0^2 (t-u_k)} \\big) $$\n",
    "\n",
    "$$X_k=t-u_k \\sim IG(\\theta_0, \\theta_1), k=1,2,...,n $$\n",
    "where $X_k$ are i.i.d Inverse Gaussian\n",
    "\n",
    "Using the max likelihood estimation, we get the estimates:\n",
    "$$\\hat{\\theta}_0=\\frac{1}{n} \\sum_{i=1}^{n} X_i=\\bar{X} $$\n",
    "$$\\frac{1}{\\hat{\\theta}_1}=\\frac{1}{n}  \\sum_{i=1}^{n} \\frac{1}{X_i}-\\frac{1}{\\bar{X}}$$\n",
    "\n",
    "Thus, the mean and the variance of the interval can be modelled as:\n",
    "$$\\mu_{RR}=\\mu(H_{u_k},\\theta)=\\theta_0 $$\n",
    "$$\\sigma_{RR}^2=\\mu(H_{u_k},\\theta)^3 \\theta_1^{-1}=\\theta_0^3 \\theta_1^{-1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IGPointProcess():\n",
    "    \"\"\"Class for Renewal Inverse Gaussian Point Process\"\"\"\n",
    "    def __init__(self, RTsInInterval):\n",
    "        self.RTsInInterval = [float(i) for i in RTsInInterval]\n",
    "        self.times = np.cumsum(RTsInInterval)\n",
    "        self.theta0 = None\n",
    "        self.theta1 = None\n",
    "        self.mu = None\n",
    "        self.sig = None\n",
    "        self.df = None\n",
    "\n",
    "    def renewalIG(self):\n",
    "        \"\"\"Determines the parameters of the Inverse Gaussian waiting time\n",
    "        Dist: MLE estimate of distribution mean (theta0), MLE estimate of \n",
    "        shape parameter (theta1), the mean (mu), and variance (sig)\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        -theta0: MLE estimate of distribution mean\n",
    "        -theta1: MLE estimate of distribution shape parameter\n",
    "        -mu: mean of IG(theta0, theta1)\n",
    "        -sig: variance of IG(theta0, theta1)\n",
    "        \"\"\"\n",
    "        #MLE estimaton\n",
    "        theta0=np.mean(self.RTsInInterval)\n",
    "        sums = 0\n",
    "        for i in self.RTsInInterval:\n",
    "            sums += np.reciprocal(i)-np.reciprocal(theta0)\n",
    "        theta1 = np.reciprocal(sums/float(len(self.RTsInInterval)))\n",
    "        #Now using the definition of mean and variance for IG\n",
    "        mu=theta0\n",
    "        sig=1./theta1*theta0**3\n",
    "        self.theta0 = theta0\n",
    "        self.theta1 = theta1\n",
    "        self.mu = mu\n",
    "        self.sig = sig\n",
    "        return theta0, theta1, mu, sig\n",
    "    \n",
    "    def print_parameters(self):\n",
    "        \"\"\"Print out fitted parameters\"\"\"\n",
    "        print(\"Theta: \", str(self.theta0), str(self.theta1))\n",
    "        print('Mean: '+str(self.mu))\n",
    "        print('Variance: '+str(self.sig))\n",
    "        \n",
    "    def plot_reaction_times(self):\n",
    "        \"\"\"Plots the raw reaction times\"\"\"\n",
    "        plt.figure()\n",
    "        plt.plot(range(len(self.RTsInInterval)), self.RTsInInterval)\n",
    "        plt.ylabel('Reaction Times [s]')\n",
    "        plt.xlabel('Time')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_distribution(self):\n",
    "        \"\"\"Plot a histogram of reaction times and the fitted\n",
    "        distribution\"\"\"\n",
    "        plt.figure()\n",
    "        wald=np.random.wald(self.theta0,self.theta1,(10000,))\n",
    "        sns.distplot(self.RTsInInterval, kde=False, norm_hist = True)\n",
    "        sns.distplot(wald, hist=False)\n",
    "        plt.xlabel('Reaction Time [s]')\n",
    "        plt.ylabel(\"Probability\")\n",
    "        plt.show()\n",
    "        \n",
    "    def sample_meanInverse(self):\n",
    "        \"\"\"Sample the distribution to produce the Mean Inverse\n",
    "        RT metric\"\"\"\n",
    "        wald=np.random.wald(self.theta0,self.theta1,(1000,))\n",
    "        inv = 1.0/wald\n",
    "        return 1000*np.mean(inv)\n",
    "    \n",
    "class Collect_IG_Data():\n",
    "    def __init__(self):\n",
    "        self.df = None\n",
    "        \n",
    "    def collect_IG_data(self, participantDict):\n",
    "        data = []\n",
    "        for participant in participantDict:\n",
    "            pvtDetail = participantDict[participant].pvtDetail\n",
    "            pvt = participantDict[participant].pvt\n",
    "            FDData = pvtDetail[(pvtDetail.DecimalTime >= participantDict[participant].startFDtime) & (pvtDetail.DecimalTime <= participantDict[participant].endFDtime)]\n",
    "            FDData_summary = pvt[(pvt.DecimalTime >= participantDict[participant].startFDtime) & (pvt.DecimalTime <= participantDict[participant].endFDtime)]\n",
    "\n",
    "            for session in sorted(list(set(FDData.SESSION))):\n",
    "                current_session_RT = FDData[FDData.SESSION == session]['RT'].values\n",
    "                current_session_RT2 = np.array([i for i in current_session_RT if i >= 100])\n",
    "                if len(current_session_RT2) != 0:\n",
    "                    inverseGaussianPP = IGPointProcess(current_session_RT2)\n",
    "                    theta0, theta1, mu, sig = inverseGaussianPP.renewalIG()\n",
    "                    data.append([participant,session,inverseGaussianPP.sample_meanInverse(),theta0,theta1])\n",
    "                        \n",
    "        a = pd.DataFrame(data, columns=['SUBJECT','SESSION','IGMeanInverseRT','IGMean','IGShape'])\n",
    "        a.to_csv(\"Datasets/IGPointProcessData.csv\", index=False)\n",
    "        self.df = a\n",
    "        \n",
    "    def saveToPVTSummaryFile(self):\n",
    "        \"\"\"Write the new features to the PVT Summary File (only\n",
    "        done if the features are not already present)\"\"\"\n",
    "        \n",
    "        pvtTest = pd.read_csv(\"PVTSummaryData.csv\", na_values = ['','.'], low_memory = False,encoding=\"latin-1\")\n",
    "        if 'IGMeanInverseRT' not in list(pvtTest):\n",
    "            merged = pd.merge(pvtTest, self.df, on=['SUBJECT', 'SESSION'])\n",
    "            merged.to_csv(\"PVTSummaryData.csv\", index=False)\n",
    "        \n",
    "    def collectAndSaveData(self,participantDict):\n",
    "        \"\"\"Collect and save data\"\"\"\n",
    "        self.collect_IG_data(participantDict)\n",
    "        self.saveToPVTSummaryFile()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History-dependent Inverse Gaussian Point Process\n",
    "Assume that we have:\n",
    "- A vector, $u$, of event times: $u = (u_1,u_2,\\ldots,u_K)$ \n",
    "- A value, $p$, which defines the number of previous intervals to consider\n",
    "- A vector, $\\theta$, of model parameters with length p+2: $\\theta = (\\theta_0, \\theta_1, \\ldots, \\theta_{p+1})$\n",
    "- A vector, $H_{u_k}$, defining the history up to event $u_k$ with length $p+1$: $H_{u_k} = (u_k, w_k, w_{k-1}, \\ldots, w_{k-(p-1)}) = (u_k, u_k-u_{k-1}, u_{k-1}-u_{k-2}, \\ldots, u_{k-(p-1)}-u_{k-p})$\n",
    "- $\\mu(H_{u_k},\\theta) = \\theta_0 + \\sum_{j=1}^{p} \\theta_j w_{k-j+1} > 0$ is the mean\n",
    "- $\\theta_{p+1} > 0$ is the scale parameter \n",
    "\n",
    "\n",
    "Given event $u_k$ and time $t$ satisfying $t>u_k$, the waiting time until the next event (i.e. length of next interval) obeys HDIG pdf: $$f(t|H_{u_k},\\theta) =\\big[\\frac{\\theta_{p+1}}{2\\pi(t-u_k)^3}\\big] ^{1/2} * \\exp{\\big(\\frac{-0.5*\\theta_{p+1}[t-u_k-\\mu(H_{u_k},\\theta)]^2}{\\mu(H_{u_k},\\theta)^2(t-u_k)}\\big)}$$\n",
    "\n",
    "This model has a mean and variance of:\n",
    "$$\\mu = \\mu(H_{u_k},\\theta)$$\n",
    "$$\\sigma^2 = \\mu(H_{u_k},\\theta)^3 \\theta_{p+1}^{-1}$$\n",
    "\n",
    "##### Local Maximum Estimation of Model Parameters\n",
    "Assume that we have:\n",
    "- A subset of $n_t$ events within the interval, $u=(u_1,u_2,\\ldots,u_{n_t})$\n",
    "- A weighting function, $w(t-u)=e^{-\\alpha(t-u)}$ where $\\alpha$ represents a weighting time constant that governs the degree of influence of a previous observation $u$ on the local likelihood at time $t$. Increasing $\\alpha$ decreases the influence of a previous observation on the local likelihood and vice versa.\n",
    "\n",
    "Then we find the MLE estimate of $\\theta_t$ by finding the $\\theta_t$ that maximizes the local log likelihood:\n",
    "$$\\log f(u|\\theta_t) = \\sum_{i=2}^{n_t} w(t-u_i)\\log f(u_{i}-u_{i-1}|H_{u_{i-1}},\\theta_t)$$\n",
    "\n",
    "**Note:** slightly different from the original log liklihood given in the paper \"A point-process model of human heartbeat intervals: new definitions of heart rate and heart rate variability\" by Barbieri 2005. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HDIGPointProcess():\n",
    "    \"\"\"Class for History-Dependent Inverse Gaussian\n",
    "    Point Process\"\"\"\n",
    "    def __init__(self, RTsInInterval,p,alpha):\n",
    "        self.RTsInInterval = [i for i in RTsInInterval]\n",
    "        self.ul = np.cumsum(RTsInInterval)\n",
    "        self.full_ul = [i for i in self.ul]\n",
    "        self.theta0 = None\n",
    "        self.theta1 = None\n",
    "        self.mu = None\n",
    "        self.sig = None\n",
    "        self.p = p\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def HDIG(self,theta):\n",
    "        \"\"\"Return the mean and standard deviation of the\n",
    "        distribution\"\"\"\n",
    "        scale=theta[-1]\n",
    "        theta0=theta[0]\n",
    "        H=self.history(self.ul,self.p)\n",
    "        mu=theta0+np.dot(H[1:self.p+1],theta[1:self.p+1])\n",
    "        sig=1./scale*mu**3\n",
    "        return mu,sig\n",
    "    \n",
    "    def HDIGpdf(self,v,H,theta):\n",
    "        \"\"\"Return value of the probability distribution\"\"\"\n",
    "        scale = theta[-1]\n",
    "        theta0 = theta[0]\n",
    "        mu = theta0+np.dot(H[1:self.p+1],theta[1:self.p+1])\n",
    "        a = float(scale)\n",
    "        b = (2*np.pi*v**3)\n",
    "        c = -0.5*float(scale)*(v-mu)**2\n",
    "        d = float(v*mu**2)\n",
    "        return 0.5*(np.log(a)-np.log(b))+c/d\n",
    "    \n",
    "    def w(self,t,ui):\n",
    "        \"\"\"Weighting function\"\"\"\n",
    "        return np.exp(-1*self.alpha*(t-ui))\n",
    "\n",
    "    def history(self, u):\n",
    "        \"\"\"Calculates the history vector\"\"\"\n",
    "        uk = u[-1] #last heartbeat\n",
    "        w = np.flip(np.diff(u),0)\n",
    "        if self.p > len(w):\n",
    "            wp = np.append(w,np.zeros(self.p-len(w)))\n",
    "        else:\n",
    "            wp = w[0:self.p]\n",
    "        H = np.append(uk, wp)\n",
    "        return H\n",
    "    \n",
    "    def localML(self,theta, t):\n",
    "        \"\"\"Calculates Log Liklihood value\"\"\"\n",
    "        nt = len(self.ul)\n",
    "        f1=0\n",
    "        for i in range(2,nt+1):\n",
    "            H = self.history(self.ul[:i-1])  \n",
    "            weight = self.w(t,self.ul[i-1])\n",
    "            fx = self.HDIGpdf(self.ul[i-1]-self.ul[i-2],H,theta)\n",
    "            f1 += weight*fx\n",
    "        return -1*f1\n",
    "    \n",
    "    def meanConstraint(self,theta, t):\n",
    "        \"\"\"Constraint that mean must be >= 100 msec as anything less\n",
    "        is not a 'valid' reaction time \"\"\"\n",
    "        H = self.history(self.ul)\n",
    "        mu = theta[0]+np.dot(H[1:self.p+1],theta[1:self.p+1])\n",
    "        return mu-100\n",
    "    \n",
    "    def meanConstraint2(self,theta, t):\n",
    "        \"\"\"Constraint that mean must be <= 10000 msec to ensure \n",
    "        that optimize routine doesn't blow up\"\"\"\n",
    "        H = self.history(self.ul)\n",
    "        mu = theta[0]+np.dot(H[1:self.p+1],theta[1:self.p+1])\n",
    "        return -mu+10000\n",
    "    \n",
    "    def scaleConstraint(self,theta,t):\n",
    "        \"\"\"Constraint that scale parameter must be positive\"\"\"\n",
    "        return theta[-1]\n",
    "\n",
    "    def optML(self,x0,args): \n",
    "        \"\"\"Optimization routine: minimizes the negative log liklihood\n",
    "        function with the constraints \"\"\"\n",
    "        con = [{'type': 'ineq', 'fun': self.meanConstraint2, 'args': args},{'type': 'ineq', 'fun': self.meanConstraint, 'args': args},{'type': 'ineq', 'fun': self.scaleConstraint, 'args': args}]\n",
    "        res=minimize(self.localML,x0,args,constraints=con,options={'disp':False})              \n",
    "        theta_est=np.array(res.x)\n",
    "        self.theta0 = theta_est[0]\n",
    "        self.theta1 = theta_est[-1]\n",
    "        H = self.history(self.ul)\n",
    "        mu = theta_est[0]+np.dot(H[1:self.p+1],theta_est[1:self.p+1])\n",
    "        self.mu = mu\n",
    "        return self.theta0, self.theta1, res.status, self.mu, theta_est\n",
    "    \n",
    "    def iterateOverTs(self,theta0_start,theta1_start):\n",
    "        \"\"\"Iterate over the reaction times and fit a distribution at each.\n",
    "        Then average the distribution parameters.\"\"\"\n",
    "        theta0_list = []\n",
    "        theta1_list = []\n",
    "        status_list = []\n",
    "        mu_list = []\n",
    "        for t in self.full_ul[self.p:]:\n",
    "            theta_start = [0.01]*(self.p+2)\n",
    "            theta_start[0] = theta0_start\n",
    "            theta_start[-1] = theta1_start\n",
    "            self.ul = self.full_ul[:self.full_ul.index(t)]\n",
    "            theta0,theta1,status,mu, thetas = self.optML(theta_start,(t,))\n",
    "            theta0_list.append(theta0)\n",
    "            theta1_list.append(theta1)\n",
    "            status_list.append(status)\n",
    "            mu_list.append(mu)\n",
    "\n",
    "        res = {'status':sum(status_list),'mu':np.mean(mu_list),'theta0':np.mean(theta0_list),'theta1':np.mean(theta1_list)}\n",
    "        return res\n",
    "        \n",
    "    def plot_distribution(self, theta0, theta1):\n",
    "        \"\"\"Plot the raw reaction times and the fitted distribution\"\"\"\n",
    "        plt.figure()\n",
    "        sns.distplot(self.RTsInInterval, kde=False, norm_hist = True)\n",
    "        wald=np.random.wald(theta0,theta1,(1000,))\n",
    "        sns.distplot(wald, hist=False)\n",
    "        plt.xlabel('Reaction Time [s]')\n",
    "        plt.ylabel(\"Probability\")\n",
    "        plt.show()\n",
    "        \n",
    "    def sample_meanInverse(self,theta0,theta1):\n",
    "        \"\"\"Sample the distribution to produce the Mean Inverse\n",
    "        RT metric\"\"\"\n",
    "        wald=np.random.wald(theta0,theta1,(10000,))\n",
    "        inv = np.reciprocal(wald)\n",
    "        return 1000*np.mean(inv)\n",
    "    \n",
    "class Collect_HDIG_Data():\n",
    "    def __init__(self, p, alpha):\n",
    "        self.p = p\n",
    "        self.alpha = alpha\n",
    "        self.data = []\n",
    "        self.df = None\n",
    "    \n",
    "    def collect_HDIG_data(self,participantDict):\n",
    "        \"\"\"Collect the HDIG parameters per session\"\"\"\n",
    "        for participant in participantDict:\n",
    "            pvtDetail = participantDict[participant].pvtDetail\n",
    "            pvt = participantDict[participant].pvt\n",
    "            FDData = pvtDetail[(pvtDetail.DecimalTime >= participantDict[participant].startFDtime) & (pvtDetail.DecimalTime <= participantDict[participant].endFDtime)]\n",
    "            for session in sorted(list(set(FDData.SESSION))):\n",
    "                current_session_RT = FDData[FDData.SESSION == session]['RT'].values\n",
    "                current_session_RT2 = np.array([i for i in current_session_RT if i >= 100])\n",
    "                if len(current_session_RT2) != 0:\n",
    "                    inverseGaussianPP = IGPointProcess(current_session_RT2)\n",
    "                    theta0, theta1, mu, sig = inverseGaussianPP.renewalIG()\n",
    "\n",
    "                    HDIGinverseGaussianPP = HDIGPointProcess(current_session_RT2,self.p,self.alpha)\n",
    "                    results = HDIGinverseGaussianPP.iterateOverTs(theta0,theta1)\n",
    "                    meaninverse = HDIGinverseGaussianPP.sample_meanInverse(results['mu'],results['theta1'])\n",
    "                    self.data.append([participant,session,meaninverse,results['theta0'],results['theta1'],results['status']])\n",
    "\n",
    "        a = pd.DataFrame(self.data, columns=['SUBJECT','SESSION','HDIGMeanInverseRT','HDIGTheta0','HDIGTheta1','status'])\n",
    "        a.to_csv(\"Datasets/HDIGPointProcessData.csv\", index=False)\n",
    "        self.df = a\n",
    "        \n",
    "    def saveToPVTSummaryFile(self):\n",
    "        \"\"\"Write the new features to the PVT Summary File (only\n",
    "        done if the features are not already present)\"\"\"\n",
    "        \n",
    "        pvtTest = pd.read_csv(\"PVTSummaryData.csv\", na_values = ['','.'], low_memory = False,encoding=\"latin-1\")\n",
    "        if 'HDIGMeanInverseRT' not in list(pvtTest):\n",
    "            merged = pd.merge(pvtTest, self.df, on=['SUBJECT', 'SESSION'])\n",
    "            merged.to_csv(\"PVTSummaryData.csv\", index=False)\n",
    "        \n",
    "    def collectAndSaveData(self,participantDict):\n",
    "        \"\"\"Collect and save data\"\"\"\n",
    "        self.collect_HDIG_data(participantDict)\n",
    "        self.saveToPVTSummaryFile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
