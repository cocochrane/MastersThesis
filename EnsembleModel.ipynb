{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook defines three classes: LinearMixedEffectsModel, MERFModel, and EnsembleModel. \n",
    "\n",
    "## 1. LinearMixedEffectsModel\n",
    "##### Initialization\n",
    "Initialized with three dictionaries, model_info, feature_info and output_info.  \n",
    "- model_info: dictionary {'modelType':type}\n",
    "- feature_info: dictionary {'random_effect_features':[], 'fixed_effect_features':[], 'intercept':True/False, 'clusterBy':featureName}\n",
    "- output_info: dictionary {'featureName': name, 'logOutput': True/False}\n",
    "\n",
    "##### Main Methods\n",
    "The method fitLME() fits the model to the specified training set and returns the results for the specified test set. The method get_results() takes multiple training/test splits (given as list of dataframes, produced from the DataCollection notebook) and returns the aggregated testing sets with their predictions. \n",
    "\n",
    "##### Other Methods\n",
    "Methods RMSE() and MAE() return these metrics on the test set. The method getModelCoefficients() returns the summary as produced from the R lme4 package.\n",
    "\n",
    "## 2. MERFModel\n",
    "##### Initialization\n",
    "Initialized with three dictionaries, model_info, feature_info and output_info.  \n",
    "- model_info: dictionary {'modelType':type}\n",
    "- feature_info: dictionary {'random_effect_features':[], 'fixed_effect_features':[], 'intercept':True/False, 'clusterBy':featureName}\n",
    "- output_info: dictionary {'featureName': name, 'logOutput': True/False}\n",
    "\n",
    "##### Main Methods\n",
    "The method fitMERF() fits the model to the specified training set and returns the results for the specified test set. The method get_results() takes multiple training/test splits (given as list of dataframes, produced from the DataCollection notebook) and returns the aggregated testing sets with their predictions. \n",
    "\n",
    "##### Other Methods\n",
    "Methods RMSE() and MAE() return these metrics on the test set. The method getMERFModelCoefficients() returns the fitted MERF model coefficients. The method getMERFconvergencePlot() returns a plot of the coefficients over each iteration of the MERF algorithm.\n",
    "\n",
    "## 3. EnsembleModel\n",
    "##### Initialization\n",
    "Initialized with the training, validation, and testing sets as well as with three dictionaries, model_info, feature_info and output_info.  \n",
    "- model_info: dictionary {'modelType':type, 'weight':#}\n",
    "- feature_info: dictionary {'random_effect_features':[], 'fixed_effect_features':[], 'intercept':True/False, 'clusterBy':featureName}\n",
    "- output_info: dictionary {'featureName': name, 'logOutput': True/False}\n",
    "\n",
    "##### Main Methods\n",
    "The method pickBestModel() uses cross-validation to choose the best feature and weight combination that minimizes validation set RMSE. The features that are tried are given by the list called featuresToTry. Once the best model is chosen, it is evaluated on the testing set. \n",
    "\n",
    "*Note*: pickBestModel was intended to work with one train/test/validate split. The training_sets, testing_sets, and validation_sets should be lists containing only 1 dataframe. Otherwise, the first train/test/split will be used to pick the best model.\n",
    "\n",
    "The method get_results() takes multiple training/test splits (given as list of dataframes, produced from the DataCollection notebook) and returns the aggregated testing sets with their predictions. \n",
    "\n",
    "##### Other Methods\n",
    "Methods RMSE() and MAE() return these metrics on the test set. The attributes merfModel and lmeModel give the class objects for the LinearMixedEffectsModel and MERFModel classes, respectively. With these class objects, all of the methods for extracting coefficients and producing convergence plots are exposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from abc import abstractmethod\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import r, pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "from itertools import combinations\n",
    "from merf.merf import MERF\n",
    "lme = importr('lme4')\n",
    "nlme = importr('nlme')\n",
    "arm = importr('arm')\n",
    "pandas2ri.activate()\n",
    "%matplotlib inline \n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel():\n",
    "    \"\"\" Class definition for an Ensemble Model using a weighted\n",
    "    average of LME and MERF predictions\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, training_sets, validation_sets, testing_sets, model_info, feature_info, output_info):\n",
    "        \"\"\" \n",
    "        Parameters:\n",
    "        ----------\n",
    "        *training_sets: list of dataframes of training data\n",
    "        *testing_sets: list of dataframes of testing data\n",
    "        *validation_sets: list of dataframes of validation data\n",
    "        *model_info = model information {'modelType':type, 'weight':#}\n",
    "        *feature_info: contains information about what features to use {'random_effect_features':[], 'fixed_effect_features':[], 'intercept':True/False, 'clusterBy':feature}\n",
    "        *output_info: {'featureName': name, 'logOutput': True/False}\n",
    "        \"\"\"\n",
    "        self.model_info = model_info\n",
    "        self.feature_info = feature_info\n",
    "        self.output_info = output_info\n",
    "        if self.output_info['log_output']:\n",
    "            self.fullOutputName = 'Log:'+self.output_info['outputDataType']+self.output_info['outputFeature']+\"(t)\"\n",
    "        else:\n",
    "            self.fullOutputName = self.output_info['outputDataType']+self.output_info['outputFeature']+\"(t)\"\n",
    "        self.merfModel = None\n",
    "        self.lmeModel = None\n",
    "        self.training_sets = training_sets\n",
    "        self.testing_sets = testing_sets\n",
    "        self.validation_sets = validation_sets\n",
    "        self.results = None\n",
    "    \n",
    "    def RMSE(self):\n",
    "        \"\"\"Gets RMSE for results\"\"\"\n",
    "        return math.sqrt(mean_squared_error(self.results[self.fullOutputName], self.results['prediction']))\n",
    "\n",
    "    def MAE(self):\n",
    "        \"\"\"Gets MAE for results\"\"\"\n",
    "        return np.mean(abs(self.results[self.fullOutputName]-self.results['prediction']))\n",
    "    \n",
    "    def get_results(self, training_sets, testing_sets, validation_sets):\n",
    "        \"\"\"Fits an Ensemble Model to every training set, makes \n",
    "        predictions on its test split, and aggregates results\n",
    "        \n",
    "         Parameters:\n",
    "        ----------\n",
    "        *training_sets: list of dataframes of training data\n",
    "        *testing_sets: list of dataframes of testing data\n",
    "        *validation_sets: list of dataframes of validation data\n",
    "        \n",
    "        Return:\n",
    "        ------\n",
    "        Dataframe of testing data with predictions\n",
    "        \"\"\"\n",
    "        \n",
    "        if 'weight' not in self.model_info or not self.feature_info:\n",
    "            print('Specify features and weights!')\n",
    "            return \n",
    "        \n",
    "        result_df = []\n",
    "        for i in range(len(training_sets)):\n",
    "            train = training_sets[i].copy()\n",
    "            validate = validation_sets[i].copy()\n",
    "            test = testing_sets[i].copy()\n",
    "            \n",
    "            feature_info = {'intercept': self.feature_info['intercept'], 'clusterBy':self.feature_info['clusterBy'], 'fixed_effect_features': self.feature_info['fixed_effect_features'], 'random_effect_features': self.feature_info['random_effect_features']}\n",
    "\n",
    "            #LME Model\n",
    "            LMEmodel = LinearMixedEffectsModel(self.model_info, feature_info, self.output_info)\n",
    "            LMEresults = LMEmodel.get_results([train],[test],[validate])\n",
    "            self.lmeModel = LMEmodel\n",
    "            \n",
    "            #MERF Model\n",
    "            MERFmodel = MERFModel(self.model_info, feature_info, self.output_info)\n",
    "            MERFresults = MERFmodel.get_results([train],[test],[validate])\n",
    "            self.merfModel = MERFmodel\n",
    "            \n",
    "            y_predMERF = MERFresults['prediction']\n",
    "            y_predLME = LMEresults['prediction']\n",
    "            averaged_predictions = []\n",
    "            for i in range(len(y_predMERF)):\n",
    "                averaged_predictions.append((self.model_info['weight']*y_predMERF[i]+(2-self.model_info['weight'])*y_predLME[i])/2.0)\n",
    "            \n",
    "            test.loc[:,'prediction'] = averaged_predictions\n",
    "            result_df.append(test)\n",
    "        final_result = pd.concat(result_df).reset_index(drop=True)\n",
    "        self.results = final_result\n",
    "        return final_result\n",
    "    \n",
    "    def pickBestModel(self,featuresToTry):\n",
    "        \"\"\" Function that uses cross-validation to choose the fixed/random\n",
    "        features to use and the weight to use that minimizes RMSE on the \n",
    "        validation set. Then the best model is evaluated on the testing set.\n",
    "        \n",
    "        For features, every combination of size 1-len(featuresToTry) for the\n",
    "        fixed features and every combination of size 0-len(featuresToTry) for\n",
    "        the random features is tried. For the weights, all values from 0\n",
    "        to 2 with a step size of 0.1 are tried.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        *featuresToTry: list of features to use in the model, each possible\n",
    "        combination of these features for the random and fixed effects is tried\n",
    "        \n",
    "        Return:\n",
    "        ------\n",
    "        Dataframe of testing data with predictions\n",
    "        \"\"\"\n",
    "        if len(self.training_sets) > 1:\n",
    "            print(\"Only able to pick best model on Predict Second Half\")\n",
    "            return\n",
    "        train = self.training_sets[0]\n",
    "        validate = self.validation_sets[0]\n",
    "        test = self.testing_sets[0]\n",
    "        \n",
    "        featWeightcombos = []\n",
    "        for n1 in range(1,len(featuresToTry)+1):\n",
    "            for fixedfeat in combinations(featuresToTry, n1): #try all combinations of size 1-len(featuresToTry) for fixed features\n",
    "                for n2 in range(len(featuresToTry)+1):\n",
    "                    for randomfeat in combinations(featuresToTry, n2): #try all combinations of size 0-len(featuresToTry) for random features\n",
    "        \n",
    "                        feature_info = {'intercept': self.feature_info['intercept'], 'clusterBy':self.feature_info['clusterBy'] , 'fixed_effect_features': fixedfeat, 'random_effect_features': randomfeat}\n",
    "\n",
    "                        #LME Model\n",
    "                        LMEmodel = LinearMixedEffectsModel(self.model_info, feature_info, self.output_info)\n",
    "                        LMEresults = LMEmodel.get_results([train],[validate])\n",
    "                        \n",
    "                        #MERF Model\n",
    "                        MERFmodel = MERFModel(self.model_info, feature_info, self.output_info)\n",
    "                        MERFresults = MERFmodel.get_results([train],[validate])\n",
    "                        \n",
    "                        y_predMERF = MERFresults['prediction']\n",
    "                        y_predLME = LMEresults['prediction']\n",
    "                        \n",
    "                        #pick weights\n",
    "                        errors = []\n",
    "                        for weight in list(np.arange(0,2.1,0.1)): #weigh\n",
    "                            averaged_predictions = []\n",
    "                            for i in range(len(y_predMERF)):\n",
    "                                averaged_predictions.append((weight*y_predMERF[i]+(2-weight)*y_predLME[i])/2.0)\n",
    "                            averageRMSE = math.sqrt(mean_squared_error(validate['PVTMeanInverseRT(t)'], averaged_predictions))\n",
    "                            errors.append([averageRMSE,weight])\n",
    "                            \n",
    "                        best_opt = sorted(errors, key=lambda x: x[0])[0]\n",
    "                        featWeightcombos.append([fixedfeat, randomfeat, best_opt])\n",
    "        best_model = sorted(featWeightcombos, key=lambda x: x[2][0])[0]\n",
    "        print('Best Model Fixed Effect Feature:',best_model[0])\n",
    "        print('Best Model Random Effect Feature:',best_model[1])\n",
    "        print('Best Model MERF Weight:',best_model[2][1])\n",
    "        \n",
    "        self.model_info['weight'] = best_model[2][1]\n",
    "        self.feature_info['fixed_effect_features'] = best_model[0]\n",
    "        self.feature_info['random_effect_features'] = best_model[1]\n",
    "        return self.get_results(self.training_sets, self.testing_sets, self.validation_sets)        \n",
    "    \n",
    "class LinearMixedEffectsModel():\n",
    "    \"\"\"Class definition for fitting and evaluating results for\n",
    "    a Linear Mixed Effect Model\"\"\"\n",
    "    \n",
    "    def __init__(self, model_info, feature_info, output_info):\n",
    "        \"\"\"Initializes Linear Mixed Effects Model (uses rpy2)\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        *model_info = model information {'modelType':type}\n",
    "        *feature_info: contains information about what features to use {'random_effect_features':[], 'fixed_effect_features':[], 'intercept':True/False, 'clusterBy':feature}\n",
    "        *output_info: {'featureName': name, 'logOutput': True/False}\n",
    "        \"\"\"\n",
    "        self.model_info = model_info\n",
    "        self.feature_info = feature_info\n",
    "        self.output_info = output_info\n",
    "        if self.output_info['log_output']:\n",
    "            self.fullOutputName = 'Log:'+self.output_info['outputDataType']+self.output_info['outputFeature']+\"(t)\"\n",
    "        else:\n",
    "            self.fullOutputName = self.output_info['outputDataType']+self.output_info['outputFeature']+\"(t)\"\n",
    "        self.formula = None\n",
    "        self.model_summary = None\n",
    "        self.results = None\n",
    "        \n",
    "    def Rify_Names(self, name):\n",
    "        \"\"\"Function that R-ifies column names in dataset (as R does not allow\n",
    "        parentheses, dashes or underscores which we use in our pandas dfs) \"\"\"\n",
    "        name = name.replace(\"(\",\"\")\n",
    "        name = name.replace(\")\",\"\")\n",
    "        name = name.replace(\"-\",\"\")\n",
    "        name = name.replace(\"_\",\"\")\n",
    "        return name\n",
    "    \n",
    "    def fitLME(self, train_sets, test_sets):\n",
    "        \"\"\"Fits a Linear Mixed Effects Model to the given\n",
    "        training set and tests on the test set\"\"\"\n",
    "        train = train_sets.copy()\n",
    "        test = test_sets.copy()\n",
    "\n",
    "        #get training data\n",
    "        y_train = train[self.fullOutputName]\n",
    "        X_train = train.drop([self.fullOutputName], axis = 1)\n",
    "\n",
    "        #get testing data\n",
    "        y_test = test[self.fullOutputName]\n",
    "        X_test = test.drop([self.fullOutputName], axis = 1)\n",
    "\n",
    "        df = X_train.assign(y=y_train)\n",
    "        df.columns = [self.Rify_Names(string) for string in df.columns]\n",
    "\n",
    "        formula = 'y~('+'+'.join([self.Rify_Names(i) for i in self.feature_info['fixed_effect_features']])+\")\"\n",
    "        if self.feature_info['intercept'] and self.feature_info['random_effect_features'] != [] and self.feature_info['random_effect_features'] != ():\n",
    "            formula += '+ (1+'+'+'.join([self.Rify_Names(i) for i in self.feature_info['random_effect_features']])+'|'+self.feature_info['clusterBy']+')'\n",
    "        elif self.feature_info['intercept'] and (self.feature_info['random_effect_features'] == [] or self.feature_info['random_effect_features'] == ()):\n",
    "            formula += '+ (1|'+self.feature_info['clusterBy']+')'\n",
    "        else:\n",
    "            formula += '+ ('+'+'.join([self.Rify_Names(i) for i in self.feature_info['random_effect_features']])+'|'+self.feature_info['clusterBy']+')'\n",
    "        self.formula = formula\n",
    "        \n",
    "        r_dataframe = pandas2ri.py2ri(df)\n",
    "        robjects.r('''\n",
    "                f <- function(train,stringFormula) {\n",
    "                    library(lme4)\n",
    "                    fitted_model <- lmer(stringFormula, data = train, REML = FALSE)\n",
    "                    return(fitted_model)\n",
    "                }\n",
    "                ''')\n",
    "        r_f = robjects.r['f']\n",
    "        fitted_model = r_f(r_dataframe,formula)\n",
    "\n",
    "        ##get coefficients\n",
    "        robjects.r('''\n",
    "                f <- function(train,stringFormula) {\n",
    "                    library(lme4)\n",
    "                    fitted_model <- lmer(stringFormula, data = train, REML = FALSE)\n",
    "                    return(summary(fitted_model))\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "        r_f = robjects.r['f']\n",
    "        model_summary = r_f(r_dataframe,formula)\n",
    "        self.model_summary = model_summary\n",
    "        ###########\n",
    "\n",
    "        df = X_test\n",
    "        df.columns = [self.Rify_Names(string) for string in df.columns]\n",
    "\n",
    "        r_dataframe = pandas2ri.py2ri(df)\n",
    "        robjects.r('''\n",
    "                f <- function(fitted_model, test) {\n",
    "                    library(lme4)\n",
    "                    pred <- predict(fitted_model, test, allow.new.levels = TRUE)\n",
    "                }\n",
    "                ''')\n",
    "        r_f = robjects.r['f']\n",
    "        response = r_f(fitted_model,r_dataframe)\n",
    "        y_pred=pandas2ri.ri2py(response)\n",
    "        return y_pred\n",
    "        \n",
    "    def get_results(self, training_sets, testing_sets, validation_sets=None):\n",
    "        \"\"\"Fits a Linear Mixed Effects Model to every training set, makes \n",
    "        predictions on its test split, and aggregates results\"\"\"\n",
    "        result_df = []\n",
    "        for i in range(len(training_sets)):\n",
    "            train = training_sets[i].copy()\n",
    "            test = testing_sets[i].copy()\n",
    "            \n",
    "            if validation_sets:\n",
    "                validate = validation_sets[i].copy()\n",
    "                all_training = pd.concat([train, validate]).reset_index(drop=True)\n",
    "                ypred = self.fitLME(all_training, test)\n",
    "            else:\n",
    "                ypred = self.fitLME(train, test)\n",
    "            test.loc[:,'prediction'] = ypred\n",
    "            result_df.append(test.copy())\n",
    "            \n",
    "        if len(result_df) == 1:\n",
    "            return result_df[0]\n",
    "        final_result = pd.concat(result_df).reset_index(drop=True)\n",
    "        self.results = final_result\n",
    "        return final_result\n",
    "            \n",
    "    def RMSE(self):\n",
    "        \"\"\"Gets RMSE for results\"\"\"\n",
    "        return math.sqrt(mean_squared_error(self.results[self.fullOutputName], self.results['prediction']))\n",
    "\n",
    "    def MAE(self):\n",
    "        \"\"\"Gets MAE for results\"\"\"\n",
    "        return np.mean(abs(self.results[self.fullOutputName]-self.results['prediction']))\n",
    "    \n",
    "    def getModelCoefficients(self):\n",
    "        \"\"\"Print summary of lme4 model\"\"\"\n",
    "        print(self.model_summary)\n",
    "        \n",
    "\n",
    "class MERFModel():\n",
    "    \"\"\"Class definition for fitting and evaluating results for\n",
    "    a Mixed Effect Random Forest Model\"\"\"\n",
    "    \n",
    "    def __init__(self, model_info, feature_info, output_info):\n",
    "        \"\"\"Initializes MERF model\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        *model_info = model information {'modelType':type}\n",
    "        *feature_info: contains information about what features to use {'random_effect_features':[], 'fixed_effect_features':[], 'intercept':True/False, 'clusterBy':feature}\n",
    "        *output_info: {'featureName': name, 'logOutput': True/False}\n",
    "        \"\"\"\n",
    "        self.model_info = model_info\n",
    "        self.feature_info = feature_info\n",
    "        self.output_info = output_info\n",
    "        if self.output_info['log_output']:\n",
    "            self.fullOutputName = 'Log:'+self.output_info['outputDataType']+self.output_info['outputFeature']+\"(t)\"\n",
    "        else:\n",
    "            self.fullOutputName = self.output_info['outputDataType']+self.output_info['outputFeature']+\"(t)\"\n",
    "        self.model_summary = None\n",
    "        self.randomFeatureList = None\n",
    "        self.fixedFeatureList = None\n",
    "        self.participantOrder = None\n",
    "        self.results = None\n",
    "    \n",
    "    def fitMERF(self, train_sets, test_sets):\n",
    "        \"\"\"Fits a MERF Model to the given\n",
    "        training set and tests on the test set\"\"\"\n",
    "        train = train_sets.copy()\n",
    "        test = test_sets.copy()\n",
    "\n",
    "        #get training data\n",
    "        y_train = train[self.fullOutputName]\n",
    "        X_train = train.loc[:,self.feature_info['fixed_effect_features']]\n",
    "        Z_train = train.loc[:,self.feature_info['random_effect_features']]\n",
    "\n",
    "        #get testing data\n",
    "        y_test = test[self.fullOutputName]\n",
    "        X_test = test.loc[:,self.feature_info['fixed_effect_features']]\n",
    "        Z_test = test.loc[:,self.feature_info['random_effect_features']]\n",
    "        \n",
    "        all_part = list(set(list(train.participantCode) + list(test.participantCode)))\n",
    "        train.loc[:,'clusterBy'] = [all_part.index(i) for i in train['participantCode']]\n",
    "        test.loc[:,'clusterBy'] = [all_part.index(i) for i in test['participantCode']]\n",
    "\n",
    "        clusters_train = train['clusterBy']\n",
    "        clusters_test = test['clusterBy']\n",
    "        \n",
    "        #Intercept\n",
    "        if self.feature_info['intercept']:\n",
    "            Z_train['intercept'] = 1\n",
    "            Z_test['intercept'] = 1 #add intercept term\n",
    "        if self.feature_info['intercept']==False and len(list(Z_train)) == 0:\n",
    "            Z_train['intercept'] = 0\n",
    "            Z_test['intercept'] = 0 #add intercept term\n",
    "            \n",
    "        mrf = MERF(n_estimators=300, max_iterations=10)\n",
    "        mrf.fit(X_train, Z_train, clusters_train, y_train)\n",
    "        y_pred = mrf.predict(X_test, Z_test, clusters_test)\n",
    "        self.model_summary = mrf\n",
    "        self.randomFeatureList = list(Z_train)\n",
    "        self.fixedFeatureList = list(X_train)\n",
    "        self.participantOrder = all_part\n",
    "        return y_pred\n",
    "        \n",
    "    def get_results(self, training_sets, testing_sets, validation_sets=None):\n",
    "        \"\"\"Fits a MERF Model to every training set, makes \n",
    "        predictions on its test split, and aggregates results\"\"\"\n",
    "        result_df = []\n",
    "        for i in range(len(training_sets)):\n",
    "            train = training_sets[i].copy()\n",
    "            test = testing_sets[i].copy()\n",
    "            \n",
    "            if validation_sets:\n",
    "                validate = validation_sets[i].copy()\n",
    "                all_training = pd.concat([train, validate]).reset_index(drop=True)\n",
    "                ypred = self.fitMERF(all_training, test)\n",
    "            else:\n",
    "                ypred = self.fitMERF(train, test)\n",
    "                \n",
    "            test.loc[:,'prediction'] = ypred\n",
    "            result_df.append(test.copy())\n",
    "            \n",
    "        if len(result_df) == 1:\n",
    "            return result_df[0]\n",
    "        final_result = pd.concat(result_df).reset_index(drop=True)\n",
    "        self.results = final_result\n",
    "        return final_result\n",
    "            \n",
    "    def RMSE(self):\n",
    "        \"\"\"Gets RMSE for results\"\"\"\n",
    "        return math.sqrt(mean_squared_error(self.results[self.fullOutputName], self.results['prediction']))\n",
    "\n",
    "    def MAE(self):\n",
    "        \"\"\"Gets MAE for results\"\"\"\n",
    "        return np.mean(abs(self.results[self.fullOutputName]-self.results['prediction']))\n",
    "    \n",
    "    def getMERFModelCoefficients(self):\n",
    "        \"\"\"Get MERF Model coefficients\"\"\"\n",
    "        model = self.model_summary\n",
    "        featureOrder = self.fixedFeatureList\n",
    "        \n",
    "        print(\"Feature importances\",list(zip(model.trained_rf.feature_importances_,featureOrder)))\n",
    "        print(\"Dhat\",model.D_hat_history[-1])\n",
    "        print(\"sigma2hat\",model.sigma2_hat_history[-1])\n",
    "        \n",
    "        coeff = model.b_hat_history[-1]\n",
    "        coeff.columns = self.randomFeatureList\n",
    "        coeff = coeff.reset_index(drop=False)\n",
    "        coeff['participantName'] = coeff.apply(self.convertNumtoName,args=(self.participantOrder,),axis=1)\n",
    "        return coeff\n",
    "    \n",
    "    def getMERFconvergencePlot(self):\n",
    "        \"\"\"Produce MERF Convergence Plot\"\"\"\n",
    "        Z_feat_order = self.randomFeatureList\n",
    "        self.plot_training_stats(self.model_summary,Z_feat_order)\n",
    "        \n",
    "    def convertNumtoName(self, row, participantList):\n",
    "        return participantList[int(row['index'])]\n",
    "\n",
    "    def plot_training_stats(self, model, attributes):\n",
    "        \"\"\"Plot training statistics\"\"\"\n",
    "        n = len(attributes)+2\n",
    "        f, axarr = plt.subplots(math.ceil(n/2.0),2, figsize=(20,10))\n",
    "\n",
    "        # Plot trace and determinant of Sigma_b (covariance matrix)\n",
    "        det_sigmaB_history = [np.linalg.det(x) for x in model.D_hat_history]\n",
    "        trace_sigmaB_history = [np.trace(x) for x in model.D_hat_history]\n",
    "        axarr[0,0].plot(det_sigmaB_history, label='Determinant of Covariance Matrix for Random Effects')\n",
    "        axarr[0,0].plot(trace_sigmaB_history, label='Trace of Covariance Matrix for Random Effects')\n",
    "        axarr[0,0].grid('on')\n",
    "        axarr[0,0].legend()\n",
    "        axarr[0,1].set_xlabel('Iteration')\n",
    "        axarr[0,0].set_title('Metrics of Variance for Random Effect Coefficients')\n",
    "\n",
    "        axarr[0,1].plot(model.sigma2_hat_history)\n",
    "        axarr[0,1].grid('on')\n",
    "        axarr[0,1].set_ylabel('Variance of Error')\n",
    "        axarr[0,1].set_xlabel('Iteration')\n",
    "\n",
    "        row = 1\n",
    "        col = 0\n",
    "        for feature in range(model.b_hat_history[0].shape[1]):\n",
    "            for cluster in range(model.b_hat_history[0].shape[0]):\n",
    "                a = [model.b_hat_history[i].iloc[cluster,feature] for i in range(len(model.b_hat_history))]\n",
    "                axarr[row,col].plot(a)\n",
    "            axarr[row,col].grid('on')\n",
    "            axarr[row,col].set_ylabel(attributes[feature])\n",
    "            axarr[row,col].set_xlabel('Iteration')\n",
    "            col += 1\n",
    "            if col > 1:\n",
    "                row += 1\n",
    "                col = 0\n",
    "\n",
    "        if n % 2 != 0:\n",
    "            axarr[math.ceil(n/2.0)-1,1].axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
